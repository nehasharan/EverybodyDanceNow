{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "dance.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPAP+24e4WbTujsIG+T5cGE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nehasharan/EverybodyDanceNow/blob/master/dance.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "99GgCfu-Cpj0",
        "outputId": "0a89407e-13ac-429b-cbc4-d81fcdb66a20"
      },
      "source": [
        "!git clone https://github.com/nehasharan/EverybodyDanceNow.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'EverybodyDanceNow'...\n",
            "remote: Enumerating objects: 5, done.\u001b[K\n",
            "remote: Counting objects: 100% (5/5), done.\u001b[K\n",
            "remote: Compressing objects: 100% (5/5), done.\u001b[K\n",
            "remote: Total 2600 (delta 1), reused 0 (delta 0), pack-reused 2595\u001b[K\n",
            "Receiving objects: 100% (2600/2600), 213.17 MiB | 52.92 MiB/s, done.\n",
            "Resolving deltas: 100% (12/12), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iFMseVtVHSFK",
        "outputId": "62a168b5-f4b6-4d50-a652-aa93e3fdee0f"
      },
      "source": [
        "!python train_fullts.py --name MY_MODEL_NAME_gl \\\n",
        "--dataroot subject4new/train \\\n",
        "--checkpoints_dir CHECKPOINTS \\\n",
        "--loadSize 512 \\\n",
        "--no_instance \\\n",
        "--no_flip \\\n",
        "--tf_log \\\n",
        "--label_nc 6"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "------------ Options -------------\n",
            "batchSize: 1\n",
            "beta1: 0.5\n",
            "checkpoints_dir: CHECKPOINTS\n",
            "continue_train: False\n",
            "dataroot: subject4new/train\n",
            "debug: False\n",
            "display_freq: 100\n",
            "display_winsize: 512\n",
            "faceGtype: unet\n",
            "face_discrim: False\n",
            "face_generator: False\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "gestures: False\n",
            "gpu_ids: [0]\n",
            "instance_feat: False\n",
            "isTrain: True\n",
            "label_feat: False\n",
            "label_nc: 6\n",
            "lambda_A: 10.0\n",
            "lambda_F: 1.0\n",
            "lambda_feat: 10.0\n",
            "loadSize: 512\n",
            "load_features: False\n",
            "load_pretrain: \n",
            "lr: 0.0002\n",
            "max_dataset_size: inf\n",
            "nThreads: 2\n",
            "n_blocks_global: 9\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 4\n",
            "n_layers_D: 3\n",
            "n_layers_D_face: 3\n",
            "n_local_enhancers: 1\n",
            "name: MY_MODEL_NAME_gl\n",
            "ndf: 64\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter: 100\n",
            "niter_decay: 100\n",
            "niter_fix_global: 0\n",
            "niter_fix_main: 0\n",
            "no_flip: True\n",
            "no_ganFeat_loss: False\n",
            "no_html: False\n",
            "no_instance: True\n",
            "no_lsgan: False\n",
            "no_vgg_loss: False\n",
            "norm: instance\n",
            "num_D: 2\n",
            "output_nc: 3\n",
            "phase: train\n",
            "pool_size: 0\n",
            "print_freq: 100\n",
            "resize_or_crop: scale_width\n",
            "save_epoch_freq: 10\n",
            "save_latest_freq: 1000\n",
            "serial_batches: False\n",
            "tf_log: True\n",
            "use_dropout: False\n",
            "use_l1: False\n",
            "which_epoch: latest\n",
            "-------------- End ----------------\n",
            "CustomDatasetDataLoader\n",
            "dataset [AlignedDataset] was created\n",
            "#training images = 100\n",
            "GlobalGenerator(\n",
            "  (model): Sequential(\n",
            "    (0): ReflectionPad2d((3, 3, 3, 3))\n",
            "    (1): Conv2d(6, 64, kernel_size=(7, 7), stride=(1, 1))\n",
            "    (2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (3): ReLU(inplace=True)\n",
            "    (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "    (5): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (6): ReLU(inplace=True)\n",
            "    (7): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "    (8): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "    (11): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): Conv2d(512, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "    (14): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (15): ReLU(inplace=True)\n",
            "    (16): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (17): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (18): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (19): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (20): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (21): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (22): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (23): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (24): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (25): ConvTranspose2d(1024, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
            "    (26): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (27): ReLU(inplace=True)\n",
            "    (28): ConvTranspose2d(512, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
            "    (29): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (30): ReLU(inplace=True)\n",
            "    (31): ConvTranspose2d(256, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
            "    (32): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (33): ReLU(inplace=True)\n",
            "    (34): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
            "    (35): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): ReflectionPad2d((3, 3, 3, 3))\n",
            "    (38): Conv2d(64, 3, kernel_size=(7, 7), stride=(1, 1))\n",
            "    (39): Tanh()\n",
            "  )\n",
            ")\n",
            "MultiscaleDiscriminator(\n",
            "  (scale0_layer0): Sequential(\n",
            "    (0): Conv2d(12, 64, kernel_size=(4, 4), stride=(2, 2), padding=(2, 2))\n",
            "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "  )\n",
            "  (scale0_layer1): Sequential(\n",
            "    (0): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(2, 2))\n",
            "    (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "  )\n",
            "  (scale0_layer2): Sequential(\n",
            "    (0): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(2, 2))\n",
            "    (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "  )\n",
            "  (scale0_layer3): Sequential(\n",
            "    (0): Conv2d(256, 512, kernel_size=(4, 4), stride=(1, 1), padding=(2, 2))\n",
            "    (1): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "  )\n",
            "  (scale0_layer4): Sequential(\n",
            "    (0): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), padding=(2, 2))\n",
            "  )\n",
            "  (scale1_layer0): Sequential(\n",
            "    (0): Conv2d(12, 64, kernel_size=(4, 4), stride=(2, 2), padding=(2, 2))\n",
            "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "  )\n",
            "  (scale1_layer1): Sequential(\n",
            "    (0): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(2, 2))\n",
            "    (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "  )\n",
            "  (scale1_layer2): Sequential(\n",
            "    (0): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(2, 2))\n",
            "    (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "  )\n",
            "  (scale1_layer3): Sequential(\n",
            "    (0): Conv2d(256, 512, kernel_size=(4, 4), stride=(1, 1), padding=(2, 2))\n",
            "    (1): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "  )\n",
            "  (scale1_layer4): Sequential(\n",
            "    (0): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), padding=(2, 2))\n",
            "  )\n",
            "  (downsample): AvgPool2d(kernel_size=3, stride=2, padding=[1, 1])\n",
            ")\n",
            "---------- Networks initialized -------------\n",
            "model [Pix2PixHDModel] was created\n",
            "WARNING:tensorflow:From /content/EverybodyDanceNow/util/visualizer.py:26: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
            "\n",
            "create web directory CHECKPOINTS/MY_MODEL_NAME_gl/web...\n",
            "(epoch: 1, iters: 100, time: 0.862) G_GAN: 1.307 G_GAN_Feat: 5.525 G_VGG: 3.656 D_real: 0.279 D_fake: 0.263 \n",
            "WARNING:tensorflow:From /content/EverybodyDanceNow/util/visualizer.py:100: The name tf.Summary is deprecated. Please use tf.compat.v1.Summary instead.\n",
            "\n",
            "End of epoch 1 / 200 \t Time Taken: 75 sec\n",
            "(epoch: 2, iters: 100, time: 0.850) G_GAN: 0.549 G_GAN_Feat: 2.955 G_VGG: 2.981 D_real: 0.556 D_fake: 0.694 \n",
            "End of epoch 2 / 200 \t Time Taken: 74 sec\n",
            "(epoch: 3, iters: 100, time: 0.845) G_GAN: 1.478 G_GAN_Feat: 2.608 G_VGG: 2.708 D_real: 0.868 D_fake: 0.200 \n",
            "End of epoch 3 / 200 \t Time Taken: 74 sec\n",
            "(epoch: 4, iters: 100, time: 0.845) G_GAN: 0.548 G_GAN_Feat: 1.971 G_VGG: 2.414 D_real: 0.329 D_fake: 0.630 \n",
            "End of epoch 4 / 200 \t Time Taken: 74 sec\n",
            "(epoch: 5, iters: 100, time: 0.848) G_GAN: 0.498 G_GAN_Feat: 1.939 G_VGG: 2.363 D_real: 0.325 D_fake: 0.608 \n",
            "End of epoch 5 / 200 \t Time Taken: 74 sec\n",
            "(epoch: 6, iters: 100, time: 0.848) G_GAN: 0.734 G_GAN_Feat: 2.252 G_VGG: 2.533 D_real: 0.510 D_fake: 0.536 \n",
            "End of epoch 6 / 200 \t Time Taken: 74 sec\n",
            "(epoch: 7, iters: 100, time: 0.849) G_GAN: 0.930 G_GAN_Feat: 1.657 G_VGG: 1.983 D_real: 0.690 D_fake: 0.330 \n",
            "End of epoch 7 / 200 \t Time Taken: 75 sec\n",
            "(epoch: 8, iters: 100, time: 0.851) G_GAN: 0.654 G_GAN_Feat: 1.765 G_VGG: 2.102 D_real: 0.507 D_fake: 0.442 \n",
            "End of epoch 8 / 200 \t Time Taken: 74 sec\n",
            "(epoch: 9, iters: 100, time: 0.845) G_GAN: 0.715 G_GAN_Feat: 1.304 G_VGG: 1.620 D_real: 0.665 D_fake: 0.409 \n",
            "End of epoch 9 / 200 \t Time Taken: 74 sec\n",
            "(epoch: 10, iters: 100, time: 0.847) G_GAN: 0.481 G_GAN_Feat: 1.678 G_VGG: 2.079 D_real: 0.343 D_fake: 0.660 \n",
            "saving the latest model (epoch 10, total_steps 1000)\n",
            "End of epoch 10 / 200 \t Time Taken: 79 sec\n",
            "saving the model at the end of epoch 10, iters 1000\n",
            "(epoch: 11, iters: 100, time: 0.837) G_GAN: 0.777 G_GAN_Feat: 1.162 G_VGG: 1.533 D_real: 0.649 D_fake: 0.427 \n",
            "End of epoch 11 / 200 \t Time Taken: 75 sec\n",
            "(epoch: 12, iters: 100, time: 0.846) G_GAN: 0.588 G_GAN_Feat: 1.518 G_VGG: 1.747 D_real: 0.440 D_fake: 0.465 \n",
            "End of epoch 12 / 200 \t Time Taken: 75 sec\n",
            "End of epoch 13 / 200 \t Time Taken: 74 sec\n",
            "(epoch: 14, iters: 100, time: 0.845) G_GAN: 0.472 G_GAN_Feat: 1.321 G_VGG: 1.471 D_real: 0.376 D_fake: 0.633 \n",
            "End of epoch 14 / 200 \t Time Taken: 75 sec\n",
            "(epoch: 15, iters: 100, time: 0.849) G_GAN: 0.738 G_GAN_Feat: 1.329 G_VGG: 1.483 D_real: 0.626 D_fake: 0.366 \n",
            "End of epoch 15 / 200 \t Time Taken: 74 sec\n",
            "(epoch: 16, iters: 100, time: 0.848) G_GAN: 0.640 G_GAN_Feat: 1.279 G_VGG: 1.521 D_real: 0.593 D_fake: 0.476 \n",
            "End of epoch 16 / 200 \t Time Taken: 74 sec\n",
            "(epoch: 17, iters: 100, time: 0.846) G_GAN: 0.903 G_GAN_Feat: 1.080 G_VGG: 1.321 D_real: 0.841 D_fake: 0.367 \n",
            "End of epoch 17 / 200 \t Time Taken: 75 sec\n",
            "(epoch: 18, iters: 100, time: 0.846) G_GAN: 0.497 G_GAN_Feat: 0.926 G_VGG: 1.262 D_real: 0.472 D_fake: 0.538 \n",
            "End of epoch 18 / 200 \t Time Taken: 74 sec\n",
            "(epoch: 19, iters: 100, time: 0.846) G_GAN: 0.455 G_GAN_Feat: 1.018 G_VGG: 1.302 D_real: 0.404 D_fake: 0.612 \n",
            "End of epoch 19 / 200 \t Time Taken: 74 sec\n",
            "(epoch: 20, iters: 100, time: 0.847) G_GAN: 0.749 G_GAN_Feat: 1.021 G_VGG: 1.312 D_real: 0.610 D_fake: 0.379 \n",
            "saving the latest model (epoch 20, total_steps 2000)\n",
            "End of epoch 20 / 200 \t Time Taken: 79 sec\n",
            "saving the model at the end of epoch 20, iters 2000\n",
            "(epoch: 21, iters: 100, time: 0.839) G_GAN: 0.725 G_GAN_Feat: 0.974 G_VGG: 1.126 D_real: 0.607 D_fake: 0.423 \n",
            "End of epoch 21 / 200 \t Time Taken: 75 sec\n",
            "(epoch: 22, iters: 100, time: 0.847) G_GAN: 0.563 G_GAN_Feat: 1.047 G_VGG: 1.177 D_real: 0.478 D_fake: 0.465 \n",
            "End of epoch 22 / 200 \t Time Taken: 75 sec\n",
            "(epoch: 23, iters: 100, time: 0.840) G_GAN: 0.809 G_GAN_Feat: 0.883 G_VGG: 1.170 D_real: 0.727 D_fake: 0.319 \n",
            "End of epoch 23 / 200 \t Time Taken: 74 sec\n",
            "(epoch: 24, iters: 100, time: 0.844) G_GAN: 0.571 G_GAN_Feat: 1.294 G_VGG: 1.890 D_real: 0.516 D_fake: 0.459 \n",
            "End of epoch 24 / 200 \t Time Taken: 74 sec\n",
            "(epoch: 25, iters: 100, time: 0.846) G_GAN: 0.558 G_GAN_Feat: 1.337 G_VGG: 1.548 D_real: 0.505 D_fake: 0.474 \n",
            "End of epoch 25 / 200 \t Time Taken: 74 sec\n",
            "(epoch: 26, iters: 100, time: 0.840) G_GAN: 0.456 G_GAN_Feat: 1.229 G_VGG: 1.327 D_real: 0.311 D_fake: 0.667 \n",
            "End of epoch 26 / 200 \t Time Taken: 74 sec\n",
            "(epoch: 27, iters: 100, time: 0.846) G_GAN: 0.602 G_GAN_Feat: 1.296 G_VGG: 1.317 D_real: 0.387 D_fake: 0.445 \n",
            "End of epoch 27 / 200 \t Time Taken: 74 sec\n",
            "(epoch: 28, iters: 100, time: 0.845) G_GAN: 0.544 G_GAN_Feat: 0.724 G_VGG: 1.094 D_real: 0.511 D_fake: 0.471 \n",
            "End of epoch 28 / 200 \t Time Taken: 74 sec\n",
            "(epoch: 29, iters: 100, time: 0.843) G_GAN: 0.482 G_GAN_Feat: 0.745 G_VGG: 1.081 D_real: 0.428 D_fake: 0.533 \n",
            "End of epoch 29 / 200 \t Time Taken: 74 sec\n",
            "(epoch: 30, iters: 100, time: 0.844) G_GAN: 0.616 G_GAN_Feat: 0.764 G_VGG: 1.022 D_real: 0.563 D_fake: 0.418 \n",
            "saving the latest model (epoch 30, total_steps 3000)\n",
            "End of epoch 30 / 200 \t Time Taken: 79 sec\n",
            "saving the model at the end of epoch 30, iters 3000\n",
            "(epoch: 31, iters: 100, time: 0.839) G_GAN: 0.511 G_GAN_Feat: 1.483 G_VGG: 1.600 D_real: 0.480 D_fake: 0.510 \n",
            "End of epoch 31 / 200 \t Time Taken: 75 sec\n",
            "(epoch: 32, iters: 100, time: 0.842) G_GAN: 0.450 G_GAN_Feat: 0.643 G_VGG: 1.061 D_real: 0.427 D_fake: 0.558 \n",
            "End of epoch 32 / 200 \t Time Taken: 74 sec\n",
            "(epoch: 33, iters: 100, time: 0.848) G_GAN: 0.454 G_GAN_Feat: 0.586 G_VGG: 0.960 D_real: 0.420 D_fake: 0.566 \n",
            "End of epoch 33 / 200 \t Time Taken: 74 sec\n",
            "(epoch: 34, iters: 100, time: 0.842) G_GAN: 0.550 G_GAN_Feat: 0.697 G_VGG: 1.031 D_real: 0.494 D_fake: 0.464 \n",
            "End of epoch 34 / 200 \t Time Taken: 74 sec\n",
            "(epoch: 35, iters: 100, time: 0.848) G_GAN: 0.581 G_GAN_Feat: 0.879 G_VGG: 1.205 D_real: 0.559 D_fake: 0.466 \n",
            "End of epoch 35 / 200 \t Time Taken: 74 sec\n",
            "(epoch: 36, iters: 100, time: 0.846) G_GAN: 0.475 G_GAN_Feat: 0.969 G_VGG: 1.182 D_real: 0.470 D_fake: 0.549 \n",
            "End of epoch 36 / 200 \t Time Taken: 74 sec\n",
            "(epoch: 37, iters: 100, time: 0.845) G_GAN: 0.452 G_GAN_Feat: 0.680 G_VGG: 0.995 D_real: 0.395 D_fake: 0.565 \n",
            "End of epoch 37 / 200 \t Time Taken: 74 sec\n",
            "(epoch: 38, iters: 100, time: 0.845) G_GAN: 0.549 G_GAN_Feat: 0.426 G_VGG: 0.913 D_real: 0.532 D_fake: 0.465 \n",
            "End of epoch 38 / 200 \t Time Taken: 74 sec\n",
            "(epoch: 39, iters: 100, time: 0.848) G_GAN: 0.467 G_GAN_Feat: 0.488 G_VGG: 1.031 D_real: 0.460 D_fake: 0.543 \n",
            "End of epoch 39 / 200 \t Time Taken: 75 sec\n",
            "(epoch: 40, iters: 100, time: 0.842) G_GAN: 0.542 G_GAN_Feat: 0.513 G_VGG: 0.995 D_real: 0.511 D_fake: 0.471 \n",
            "saving the latest model (epoch 40, total_steps 4000)\n",
            "End of epoch 40 / 200 \t Time Taken: 79 sec\n",
            "saving the model at the end of epoch 40, iters 4000\n",
            "(epoch: 41, iters: 100, time: 0.841) G_GAN: 0.598 G_GAN_Feat: 0.573 G_VGG: 0.912 D_real: 0.537 D_fake: 0.428 \n",
            "End of epoch 41 / 200 \t Time Taken: 75 sec\n",
            "(epoch: 42, iters: 100, time: 0.848) G_GAN: 0.549 G_GAN_Feat: 0.800 G_VGG: 1.235 D_real: 0.495 D_fake: 0.467 \n",
            "End of epoch 42 / 200 \t Time Taken: 75 sec\n",
            "(epoch: 43, iters: 100, time: 0.849) G_GAN: 0.545 G_GAN_Feat: 0.777 G_VGG: 1.733 D_real: 0.472 D_fake: 0.470 \n",
            "End of epoch 43 / 200 \t Time Taken: 74 sec\n",
            "(epoch: 44, iters: 100, time: 0.849) G_GAN: 0.483 G_GAN_Feat: 0.584 G_VGG: 1.014 D_real: 0.476 D_fake: 0.546 \n",
            "End of epoch 44 / 200 \t Time Taken: 74 sec\n",
            "(epoch: 45, iters: 100, time: 0.846) G_GAN: 0.551 G_GAN_Feat: 0.754 G_VGG: 1.177 D_real: 0.508 D_fake: 0.472 \n",
            "End of epoch 45 / 200 \t Time Taken: 74 sec\n",
            "(epoch: 46, iters: 100, time: 0.842) G_GAN: 0.501 G_GAN_Feat: 0.422 G_VGG: 0.974 D_real: 0.493 D_fake: 0.532 \n",
            "End of epoch 46 / 200 \t Time Taken: 75 sec\n",
            "(epoch: 47, iters: 100, time: 0.844) G_GAN: 0.419 G_GAN_Feat: 0.480 G_VGG: 0.864 D_real: 0.402 D_fake: 0.630 \n",
            "End of epoch 47 / 200 \t Time Taken: 74 sec\n",
            "(epoch: 48, iters: 100, time: 0.841) G_GAN: 0.594 G_GAN_Feat: 0.485 G_VGG: 0.910 D_real: 0.549 D_fake: 0.446 \n",
            "End of epoch 48 / 200 \t Time Taken: 74 sec\n",
            "(epoch: 49, iters: 100, time: 0.848) G_GAN: 0.679 G_GAN_Feat: 0.560 G_VGG: 0.926 D_real: 0.649 D_fake: 0.402 \n",
            "End of epoch 49 / 200 \t Time Taken: 74 sec\n",
            "(epoch: 50, iters: 100, time: 0.847) G_GAN: 0.557 G_GAN_Feat: 0.586 G_VGG: 0.946 D_real: 0.527 D_fake: 0.473 \n",
            "saving the latest model (epoch 50, total_steps 5000)\n",
            "End of epoch 50 / 200 \t Time Taken: 79 sec\n",
            "saving the model at the end of epoch 50, iters 5000\n",
            "(epoch: 51, iters: 100, time: 0.839) G_GAN: 0.587 G_GAN_Feat: 0.702 G_VGG: 1.045 D_real: 0.507 D_fake: 0.442 \n",
            "End of epoch 51 / 200 \t Time Taken: 75 sec\n",
            "(epoch: 52, iters: 100, time: 0.840) G_GAN: 0.611 G_GAN_Feat: 0.657 G_VGG: 0.935 D_real: 0.604 D_fake: 0.428 \n",
            "End of epoch 52 / 200 \t Time Taken: 74 sec\n",
            "(epoch: 53, iters: 100, time: 0.845) G_GAN: 0.495 G_GAN_Feat: 0.466 G_VGG: 0.930 D_real: 0.479 D_fake: 0.524 \n",
            "End of epoch 53 / 200 \t Time Taken: 74 sec\n",
            "(epoch: 54, iters: 100, time: 0.842) G_GAN: 0.722 G_GAN_Feat: 0.593 G_VGG: 0.897 D_real: 0.672 D_fake: 0.365 \n",
            "End of epoch 54 / 200 \t Time Taken: 74 sec\n",
            "(epoch: 55, iters: 100, time: 0.847) G_GAN: 0.550 G_GAN_Feat: 0.471 G_VGG: 0.845 D_real: 0.503 D_fake: 0.495 \n",
            "End of epoch 55 / 200 \t Time Taken: 74 sec\n",
            "(epoch: 56, iters: 100, time: 0.847) G_GAN: 0.768 G_GAN_Feat: 0.616 G_VGG: 0.912 D_real: 0.644 D_fake: 0.316 \n",
            "End of epoch 56 / 200 \t Time Taken: 75 sec\n",
            "(epoch: 57, iters: 100, time: 0.845) G_GAN: 0.485 G_GAN_Feat: 0.565 G_VGG: 0.950 D_real: 0.470 D_fake: 0.697 \n",
            "End of epoch 57 / 200 \t Time Taken: 75 sec\n",
            "(epoch: 58, iters: 100, time: 0.852) G_GAN: 0.455 G_GAN_Feat: 0.492 G_VGG: 0.892 D_real: 0.436 D_fake: 0.560 \n",
            "End of epoch 58 / 200 \t Time Taken: 74 sec\n",
            "(epoch: 59, iters: 100, time: 0.840) G_GAN: 0.436 G_GAN_Feat: 0.560 G_VGG: 0.791 D_real: 0.313 D_fake: 0.701 \n",
            "End of epoch 59 / 200 \t Time Taken: 74 sec\n",
            "(epoch: 60, iters: 100, time: 0.846) G_GAN: 0.959 G_GAN_Feat: 0.730 G_VGG: 0.773 D_real: 0.657 D_fake: 0.240 \n",
            "saving the latest model (epoch 60, total_steps 6000)\n",
            "End of epoch 60 / 200 \t Time Taken: 79 sec\n",
            "saving the model at the end of epoch 60, iters 6000\n",
            "(epoch: 61, iters: 100, time: 0.836) G_GAN: 0.786 G_GAN_Feat: 0.554 G_VGG: 0.837 D_real: 0.666 D_fake: 0.336 \n",
            "End of epoch 61 / 200 \t Time Taken: 75 sec\n",
            "(epoch: 62, iters: 100, time: 0.846) G_GAN: 0.496 G_GAN_Feat: 0.243 G_VGG: 0.753 D_real: 0.498 D_fake: 0.513 \n",
            "End of epoch 62 / 200 \t Time Taken: 75 sec\n",
            "(epoch: 63, iters: 100, time: 0.848) G_GAN: 0.492 G_GAN_Feat: 0.291 G_VGG: 0.793 D_real: 0.483 D_fake: 0.516 \n",
            "End of epoch 63 / 200 \t Time Taken: 74 sec\n",
            "(epoch: 64, iters: 100, time: 0.844) G_GAN: 0.584 G_GAN_Feat: 0.279 G_VGG: 0.772 D_real: 0.579 D_fake: 0.435 \n",
            "End of epoch 64 / 200 \t Time Taken: 75 sec\n",
            "(epoch: 65, iters: 100, time: 0.846) G_GAN: 0.465 G_GAN_Feat: 0.289 G_VGG: 0.850 D_real: 0.458 D_fake: 0.542 \n",
            "End of epoch 65 / 200 \t Time Taken: 75 sec\n",
            "(epoch: 66, iters: 100, time: 0.846) G_GAN: 0.543 G_GAN_Feat: 0.319 G_VGG: 0.783 D_real: 0.541 D_fake: 0.463 \n",
            "End of epoch 66 / 200 \t Time Taken: 74 sec\n",
            "(epoch: 67, iters: 100, time: 0.846) G_GAN: 0.550 G_GAN_Feat: 0.311 G_VGG: 0.702 D_real: 0.542 D_fake: 0.463 \n",
            "End of epoch 67 / 200 \t Time Taken: 75 sec\n",
            "(epoch: 68, iters: 100, time: 0.842) G_GAN: 0.516 G_GAN_Feat: 0.261 G_VGG: 0.752 D_real: 0.514 D_fake: 0.487 \n",
            "End of epoch 68 / 200 \t Time Taken: 74 sec\n",
            "(epoch: 69, iters: 100, time: 0.851) G_GAN: 0.505 G_GAN_Feat: 0.285 G_VGG: 0.762 D_real: 0.493 D_fake: 0.541 \n",
            "End of epoch 69 / 200 \t Time Taken: 74 sec\n",
            "(epoch: 70, iters: 100, time: 0.843) G_GAN: 0.455 G_GAN_Feat: 0.316 G_VGG: 0.843 D_real: 0.449 D_fake: 0.552 \n",
            "saving the latest model (epoch 70, total_steps 7000)\n",
            "End of epoch 70 / 200 \t Time Taken: 79 sec\n",
            "saving the model at the end of epoch 70, iters 7000\n",
            "(epoch: 71, iters: 100, time: 0.838) G_GAN: 0.392 G_GAN_Feat: 0.301 G_VGG: 0.754 D_real: 0.388 D_fake: 0.650 \n",
            "End of epoch 71 / 200 \t Time Taken: 75 sec\n",
            "(epoch: 72, iters: 100, time: 0.843) G_GAN: 0.501 G_GAN_Feat: 0.338 G_VGG: 0.735 D_real: 0.493 D_fake: 0.566 \n",
            "End of epoch 72 / 200 \t Time Taken: 75 sec\n",
            "(epoch: 73, iters: 100, time: 0.846) G_GAN: 0.524 G_GAN_Feat: 0.471 G_VGG: 1.081 D_real: 0.520 D_fake: 0.748 \n",
            "End of epoch 73 / 200 \t Time Taken: 74 sec\n",
            "(epoch: 74, iters: 100, time: 0.847) G_GAN: 0.543 G_GAN_Feat: 0.508 G_VGG: 0.978 D_real: 0.481 D_fake: 0.703 \n",
            "End of epoch 74 / 200 \t Time Taken: 74 sec\n",
            "(epoch: 75, iters: 100, time: 0.847) G_GAN: 0.486 G_GAN_Feat: 0.451 G_VGG: 0.760 D_real: 0.366 D_fake: 0.745 \n",
            "End of epoch 75 / 200 \t Time Taken: 74 sec\n",
            "(epoch: 76, iters: 100, time: 0.849) G_GAN: 0.590 G_GAN_Feat: 0.427 G_VGG: 0.784 D_real: 0.530 D_fake: 0.712 \n",
            "End of epoch 76 / 200 \t Time Taken: 74 sec\n",
            "(epoch: 77, iters: 100, time: 0.844) G_GAN: 0.443 G_GAN_Feat: 0.346 G_VGG: 0.821 D_real: 0.442 D_fake: 0.574 \n",
            "End of epoch 77 / 200 \t Time Taken: 74 sec\n",
            "(epoch: 78, iters: 100, time: 0.845) G_GAN: 0.580 G_GAN_Feat: 0.302 G_VGG: 0.747 D_real: 0.577 D_fake: 0.433 \n",
            "End of epoch 78 / 200 \t Time Taken: 74 sec\n",
            "(epoch: 79, iters: 100, time: 0.845) G_GAN: 0.451 G_GAN_Feat: 0.500 G_VGG: 0.764 D_real: 0.427 D_fake: 0.607 \n",
            "End of epoch 79 / 200 \t Time Taken: 75 sec\n",
            "(epoch: 80, iters: 100, time: 0.842) G_GAN: 0.692 G_GAN_Feat: 0.430 G_VGG: 0.752 D_real: 0.642 D_fake: 0.389 \n",
            "saving the latest model (epoch 80, total_steps 8000)\n",
            "End of epoch 80 / 200 \t Time Taken: 79 sec\n",
            "saving the model at the end of epoch 80, iters 8000\n",
            "(epoch: 81, iters: 100, time: 0.835) G_GAN: 0.553 G_GAN_Feat: 0.576 G_VGG: 0.857 D_real: 0.545 D_fake: 0.467 \n",
            "End of epoch 81 / 200 \t Time Taken: 75 sec\n",
            "(epoch: 82, iters: 100, time: 0.844) G_GAN: 0.638 G_GAN_Feat: 0.225 G_VGG: 0.658 D_real: 0.639 D_fake: 0.417 \n",
            "End of epoch 82 / 200 \t Time Taken: 74 sec\n",
            "(epoch: 83, iters: 100, time: 0.847) G_GAN: 0.494 G_GAN_Feat: 0.210 G_VGG: 0.717 D_real: 0.491 D_fake: 0.507 \n",
            "End of epoch 83 / 200 \t Time Taken: 74 sec\n",
            "(epoch: 84, iters: 100, time: 0.848) G_GAN: 0.516 G_GAN_Feat: 0.235 G_VGG: 0.741 D_real: 0.515 D_fake: 0.487 \n",
            "End of epoch 84 / 200 \t Time Taken: 74 sec\n",
            "(epoch: 85, iters: 100, time: 0.846) G_GAN: 0.565 G_GAN_Feat: 0.205 G_VGG: 0.699 D_real: 0.559 D_fake: 0.445 \n",
            "End of epoch 85 / 200 \t Time Taken: 74 sec\n",
            "(epoch: 86, iters: 100, time: 0.845) G_GAN: 0.494 G_GAN_Feat: 0.280 G_VGG: 0.788 D_real: 0.493 D_fake: 0.508 \n",
            "End of epoch 86 / 200 \t Time Taken: 75 sec\n",
            "(epoch: 87, iters: 100, time: 0.845) G_GAN: 0.480 G_GAN_Feat: 0.340 G_VGG: 0.694 D_real: 0.466 D_fake: 0.526 \n",
            "End of epoch 87 / 200 \t Time Taken: 75 sec\n",
            "(epoch: 88, iters: 100, time: 0.843) G_GAN: 0.685 G_GAN_Feat: 0.379 G_VGG: 0.685 D_real: 0.614 D_fake: 0.440 \n",
            "End of epoch 88 / 200 \t Time Taken: 75 sec\n",
            "(epoch: 89, iters: 100, time: 0.849) G_GAN: 0.592 G_GAN_Feat: 0.438 G_VGG: 0.760 D_real: 0.450 D_fake: 0.458 \n",
            "End of epoch 89 / 200 \t Time Taken: 75 sec\n",
            "(epoch: 90, iters: 100, time: 0.848) G_GAN: 0.525 G_GAN_Feat: 0.531 G_VGG: 0.762 D_real: 0.448 D_fake: 0.507 \n",
            "saving the latest model (epoch 90, total_steps 9000)\n",
            "End of epoch 90 / 200 \t Time Taken: 79 sec\n",
            "saving the model at the end of epoch 90, iters 9000\n",
            "(epoch: 91, iters: 100, time: 0.838) G_GAN: 0.529 G_GAN_Feat: 0.520 G_VGG: 0.751 D_real: 0.406 D_fake: 0.528 \n",
            "End of epoch 91 / 200 \t Time Taken: 75 sec\n",
            "(epoch: 92, iters: 100, time: 0.844) G_GAN: 0.653 G_GAN_Feat: 0.419 G_VGG: 0.681 D_real: 0.484 D_fake: 0.429 \n",
            "End of epoch 92 / 200 \t Time Taken: 75 sec\n",
            "(epoch: 93, iters: 100, time: 0.846) G_GAN: 0.474 G_GAN_Feat: 0.404 G_VGG: 0.703 D_real: 0.463 D_fake: 0.535 \n",
            "End of epoch 93 / 200 \t Time Taken: 74 sec\n",
            "(epoch: 94, iters: 100, time: 0.845) G_GAN: 0.635 G_GAN_Feat: 0.444 G_VGG: 0.733 D_real: 0.643 D_fake: 0.432 \n",
            "End of epoch 94 / 200 \t Time Taken: 75 sec\n",
            "(epoch: 95, iters: 100, time: 0.842) G_GAN: 0.535 G_GAN_Feat: 0.337 G_VGG: 0.668 D_real: 0.531 D_fake: 0.479 \n",
            "End of epoch 95 / 200 \t Time Taken: 74 sec\n",
            "(epoch: 96, iters: 100, time: 0.845) G_GAN: 0.512 G_GAN_Feat: 0.325 G_VGG: 0.661 D_real: 0.500 D_fake: 0.517 \n",
            "End of epoch 96 / 200 \t Time Taken: 75 sec\n",
            "(epoch: 97, iters: 100, time: 0.844) G_GAN: 0.464 G_GAN_Feat: 0.746 G_VGG: 1.136 D_real: 0.442 D_fake: 0.567 \n",
            "End of epoch 97 / 200 \t Time Taken: 74 sec\n",
            "(epoch: 98, iters: 100, time: 0.845) G_GAN: 0.517 G_GAN_Feat: 0.399 G_VGG: 0.732 D_real: 0.498 D_fake: 0.492 \n",
            "End of epoch 98 / 200 \t Time Taken: 74 sec\n",
            "(epoch: 99, iters: 100, time: 0.851) G_GAN: 0.527 G_GAN_Feat: 0.430 G_VGG: 0.685 D_real: 0.523 D_fake: 0.488 \n",
            "End of epoch 99 / 200 \t Time Taken: 75 sec\n",
            "(epoch: 100, iters: 100, time: 0.844) G_GAN: 0.463 G_GAN_Feat: 0.444 G_VGG: 0.672 D_real: 0.444 D_fake: 0.555 \n",
            "saving the latest model (epoch 100, total_steps 10000)\n",
            "End of epoch 100 / 200 \t Time Taken: 79 sec\n",
            "saving the model at the end of epoch 100, iters 10000\n",
            "(epoch: 101, iters: 100, time: 0.838) G_GAN: 0.429 G_GAN_Feat: 0.479 G_VGG: 0.693 D_real: 0.428 D_fake: 0.626 \n",
            "End of epoch 101 / 200 \t Time Taken: 75 sec\n",
            "update learning rate: 0.000200 -> 0.000198\n",
            "(epoch: 102, iters: 100, time: 0.846) G_GAN: 0.482 G_GAN_Feat: 0.429 G_VGG: 0.657 D_real: 0.468 D_fake: 0.548 \n",
            "End of epoch 102 / 200 \t Time Taken: 75 sec\n",
            "update learning rate: 0.000198 -> 0.000196\n",
            "(epoch: 103, iters: 100, time: 0.849) G_GAN: 0.481 G_GAN_Feat: 0.386 G_VGG: 0.677 D_real: 0.466 D_fake: 0.527 \n",
            "End of epoch 103 / 200 \t Time Taken: 74 sec\n",
            "update learning rate: 0.000196 -> 0.000194\n",
            "(epoch: 104, iters: 100, time: 0.845) G_GAN: 0.456 G_GAN_Feat: 0.472 G_VGG: 0.663 D_real: 0.431 D_fake: 0.557 \n",
            "End of epoch 104 / 200 \t Time Taken: 75 sec\n",
            "update learning rate: 0.000194 -> 0.000192\n",
            "(epoch: 105, iters: 100, time: 0.846) G_GAN: 0.543 G_GAN_Feat: 0.495 G_VGG: 0.695 D_real: 0.509 D_fake: 0.469 \n",
            "End of epoch 105 / 200 \t Time Taken: 74 sec\n",
            "update learning rate: 0.000192 -> 0.000190\n",
            "(epoch: 106, iters: 100, time: 0.852) G_GAN: 0.386 G_GAN_Feat: 0.364 G_VGG: 0.604 D_real: 0.377 D_fake: 0.655 \n",
            "End of epoch 106 / 200 \t Time Taken: 74 sec\n",
            "update learning rate: 0.000190 -> 0.000188\n",
            "(epoch: 107, iters: 100, time: 0.844) G_GAN: 0.374 G_GAN_Feat: 0.529 G_VGG: 0.674 D_real: 0.343 D_fake: 0.725 \n",
            "End of epoch 107 / 200 \t Time Taken: 75 sec\n",
            "update learning rate: 0.000188 -> 0.000186\n",
            "(epoch: 108, iters: 100, time: 0.845) G_GAN: 0.666 G_GAN_Feat: 0.560 G_VGG: 0.703 D_real: 0.625 D_fake: 0.391 \n",
            "End of epoch 108 / 200 \t Time Taken: 74 sec\n",
            "update learning rate: 0.000186 -> 0.000184\n",
            "(epoch: 109, iters: 100, time: 0.845) G_GAN: 0.596 G_GAN_Feat: 0.617 G_VGG: 0.755 D_real: 0.557 D_fake: 0.433 \n",
            "End of epoch 109 / 200 \t Time Taken: 75 sec\n",
            "update learning rate: 0.000184 -> 0.000182\n",
            "(epoch: 110, iters: 100, time: 0.845) G_GAN: 0.639 G_GAN_Feat: 0.670 G_VGG: 0.815 D_real: 0.582 D_fake: 0.403 \n",
            "saving the latest model (epoch 110, total_steps 11000)\n",
            "End of epoch 110 / 200 \t Time Taken: 79 sec\n",
            "saving the model at the end of epoch 110, iters 11000\n",
            "update learning rate: 0.000182 -> 0.000180\n",
            "(epoch: 111, iters: 100, time: 0.839) G_GAN: 0.501 G_GAN_Feat: 0.598 G_VGG: 0.661 D_real: 0.451 D_fake: 0.522 \n",
            "End of epoch 111 / 200 \t Time Taken: 75 sec\n",
            "update learning rate: 0.000180 -> 0.000178\n",
            "(epoch: 112, iters: 100, time: 0.846) G_GAN: 0.605 G_GAN_Feat: 0.575 G_VGG: 0.625 D_real: 0.586 D_fake: 0.438 \n",
            "End of epoch 112 / 200 \t Time Taken: 75 sec\n",
            "update learning rate: 0.000178 -> 0.000176\n",
            "(epoch: 113, iters: 100, time: 0.847) G_GAN: 0.501 G_GAN_Feat: 0.689 G_VGG: 0.720 D_real: 0.494 D_fake: 0.521 \n",
            "End of epoch 113 / 200 \t Time Taken: 75 sec\n",
            "update learning rate: 0.000176 -> 0.000174\n",
            "(epoch: 114, iters: 100, time: 0.847) G_GAN: 0.688 G_GAN_Feat: 0.697 G_VGG: 0.638 D_real: 0.639 D_fake: 0.371 \n",
            "End of epoch 114 / 200 \t Time Taken: 75 sec\n",
            "update learning rate: 0.000174 -> 0.000172\n",
            "(epoch: 115, iters: 100, time: 0.843) G_GAN: 0.510 G_GAN_Feat: 0.671 G_VGG: 0.683 D_real: 0.505 D_fake: 0.507 \n",
            "End of epoch 115 / 200 \t Time Taken: 75 sec\n",
            "update learning rate: 0.000172 -> 0.000170\n",
            "(epoch: 116, iters: 100, time: 0.846) G_GAN: 0.448 G_GAN_Feat: 0.619 G_VGG: 0.557 D_real: 0.418 D_fake: 0.574 \n",
            "End of epoch 116 / 200 \t Time Taken: 74 sec\n",
            "update learning rate: 0.000170 -> 0.000168\n",
            "(epoch: 117, iters: 100, time: 0.849) G_GAN: 0.649 G_GAN_Feat: 0.770 G_VGG: 0.667 D_real: 0.592 D_fake: 0.386 \n",
            "End of epoch 117 / 200 \t Time Taken: 75 sec\n",
            "update learning rate: 0.000168 -> 0.000166\n",
            "(epoch: 118, iters: 100, time: 0.844) G_GAN: 0.454 G_GAN_Feat: 0.624 G_VGG: 0.540 D_real: 0.428 D_fake: 0.583 \n",
            "End of epoch 118 / 200 \t Time Taken: 74 sec\n",
            "update learning rate: 0.000166 -> 0.000164\n",
            "(epoch: 119, iters: 100, time: 0.851) G_GAN: 0.592 G_GAN_Feat: 0.729 G_VGG: 0.648 D_real: 0.541 D_fake: 0.431 \n",
            "End of epoch 119 / 200 \t Time Taken: 75 sec\n",
            "update learning rate: 0.000164 -> 0.000162\n",
            "(epoch: 120, iters: 100, time: 0.845) G_GAN: 0.356 G_GAN_Feat: 0.754 G_VGG: 0.590 D_real: 0.338 D_fake: 0.761 \n",
            "saving the latest model (epoch 120, total_steps 12000)\n",
            "End of epoch 120 / 200 \t Time Taken: 79 sec\n",
            "saving the model at the end of epoch 120, iters 12000\n",
            "update learning rate: 0.000162 -> 0.000160\n",
            "(epoch: 121, iters: 100, time: 0.837) G_GAN: 0.500 G_GAN_Feat: 0.799 G_VGG: 0.616 D_real: 0.463 D_fake: 0.519 \n",
            "End of epoch 121 / 200 \t Time Taken: 75 sec\n",
            "update learning rate: 0.000160 -> 0.000158\n",
            "(epoch: 122, iters: 100, time: 0.845) G_GAN: 0.642 G_GAN_Feat: 0.814 G_VGG: 0.613 D_real: 0.593 D_fake: 0.409 \n",
            "End of epoch 122 / 200 \t Time Taken: 75 sec\n",
            "update learning rate: 0.000158 -> 0.000156\n",
            "(epoch: 123, iters: 100, time: 0.850) G_GAN: 0.550 G_GAN_Feat: 0.730 G_VGG: 0.580 D_real: 0.531 D_fake: 0.473 \n",
            "End of epoch 123 / 200 \t Time Taken: 75 sec\n",
            "update learning rate: 0.000156 -> 0.000154\n",
            "(epoch: 124, iters: 100, time: 0.846) G_GAN: 0.705 G_GAN_Feat: 0.890 G_VGG: 0.607 D_real: 0.654 D_fake: 0.379 \n",
            "End of epoch 124 / 200 \t Time Taken: 75 sec\n",
            "update learning rate: 0.000154 -> 0.000152\n",
            "(epoch: 125, iters: 100, time: 0.845) G_GAN: 0.713 G_GAN_Feat: 0.899 G_VGG: 0.643 D_real: 0.671 D_fake: 0.366 \n",
            "End of epoch 125 / 200 \t Time Taken: 74 sec\n",
            "update learning rate: 0.000152 -> 0.000150\n",
            "(epoch: 126, iters: 100, time: 0.851) G_GAN: 0.507 G_GAN_Feat: 0.994 G_VGG: 0.593 D_real: 0.418 D_fake: 0.507 \n",
            "End of epoch 126 / 200 \t Time Taken: 75 sec\n",
            "update learning rate: 0.000150 -> 0.000148\n",
            "(epoch: 127, iters: 100, time: 0.848) G_GAN: 0.549 G_GAN_Feat: 0.573 G_VGG: 0.587 D_real: 0.533 D_fake: 0.468 \n",
            "End of epoch 127 / 200 \t Time Taken: 75 sec\n",
            "update learning rate: 0.000148 -> 0.000146\n",
            "(epoch: 128, iters: 100, time: 0.843) G_GAN: 0.417 G_GAN_Feat: 0.820 G_VGG: 0.601 D_real: 0.369 D_fake: 0.610 \n",
            "End of epoch 128 / 200 \t Time Taken: 74 sec\n",
            "update learning rate: 0.000146 -> 0.000144\n",
            "(epoch: 129, iters: 100, time: 0.848) G_GAN: 0.588 G_GAN_Feat: 0.964 G_VGG: 0.657 D_real: 0.536 D_fake: 0.448 \n",
            "End of epoch 129 / 200 \t Time Taken: 75 sec\n",
            "update learning rate: 0.000144 -> 0.000142\n",
            "(epoch: 130, iters: 100, time: 0.846) G_GAN: 0.499 G_GAN_Feat: 1.027 G_VGG: 0.581 D_real: 0.435 D_fake: 0.517 \n",
            "saving the latest model (epoch 130, total_steps 13000)\n",
            "End of epoch 130 / 200 \t Time Taken: 79 sec\n",
            "saving the model at the end of epoch 130, iters 13000\n",
            "update learning rate: 0.000142 -> 0.000140\n",
            "(epoch: 131, iters: 100, time: 0.837) G_GAN: 0.498 G_GAN_Feat: 1.063 G_VGG: 0.573 D_real: 0.405 D_fake: 0.536 \n",
            "End of epoch 131 / 200 \t Time Taken: 75 sec\n",
            "update learning rate: 0.000140 -> 0.000138\n",
            "(epoch: 132, iters: 100, time: 0.845) G_GAN: 0.803 G_GAN_Feat: 1.194 G_VGG: 0.574 D_real: 0.674 D_fake: 0.322 \n",
            "End of epoch 132 / 200 \t Time Taken: 75 sec\n",
            "update learning rate: 0.000138 -> 0.000136\n",
            "(epoch: 133, iters: 100, time: 0.847) G_GAN: 0.494 G_GAN_Feat: 1.026 G_VGG: 0.616 D_real: 0.454 D_fake: 0.596 \n",
            "End of epoch 133 / 200 \t Time Taken: 74 sec\n",
            "update learning rate: 0.000136 -> 0.000134\n",
            "(epoch: 134, iters: 100, time: 0.847) G_GAN: 0.658 G_GAN_Feat: 1.513 G_VGG: 0.652 D_real: 0.536 D_fake: 0.418 \n",
            "End of epoch 134 / 200 \t Time Taken: 75 sec\n",
            "update learning rate: 0.000134 -> 0.000132\n",
            "(epoch: 135, iters: 100, time: 0.845) G_GAN: 0.570 G_GAN_Feat: 1.479 G_VGG: 0.587 D_real: 0.466 D_fake: 0.467 \n",
            "End of epoch 135 / 200 \t Time Taken: 75 sec\n",
            "update learning rate: 0.000132 -> 0.000130\n",
            "(epoch: 136, iters: 100, time: 0.848) G_GAN: 0.535 G_GAN_Feat: 1.388 G_VGG: 0.581 D_real: 0.449 D_fake: 0.506 \n",
            "End of epoch 136 / 200 \t Time Taken: 74 sec\n",
            "update learning rate: 0.000130 -> 0.000128\n",
            "(epoch: 137, iters: 100, time: 0.848) G_GAN: 0.609 G_GAN_Feat: 1.634 G_VGG: 0.561 D_real: 0.524 D_fake: 0.430 \n",
            "End of epoch 137 / 200 \t Time Taken: 75 sec\n",
            "update learning rate: 0.000128 -> 0.000126\n",
            "(epoch: 138, iters: 100, time: 0.843) G_GAN: 0.570 G_GAN_Feat: 1.659 G_VGG: 0.632 D_real: 0.457 D_fake: 0.486 \n",
            "End of epoch 138 / 200 \t Time Taken: 75 sec\n",
            "update learning rate: 0.000126 -> 0.000124\n",
            "(epoch: 139, iters: 100, time: 0.845) G_GAN: 0.576 G_GAN_Feat: 1.820 G_VGG: 0.712 D_real: 0.444 D_fake: 0.470 \n",
            "End of epoch 139 / 200 \t Time Taken: 75 sec\n",
            "update learning rate: 0.000124 -> 0.000122\n",
            "(epoch: 140, iters: 100, time: 0.843) G_GAN: 0.474 G_GAN_Feat: 1.614 G_VGG: 0.536 D_real: 0.392 D_fake: 0.552 \n",
            "saving the latest model (epoch 140, total_steps 14000)\n",
            "End of epoch 140 / 200 \t Time Taken: 79 sec\n",
            "saving the model at the end of epoch 140, iters 14000\n",
            "update learning rate: 0.000122 -> 0.000120\n",
            "(epoch: 141, iters: 100, time: 0.843) G_GAN: 0.479 G_GAN_Feat: 0.728 G_VGG: 0.574 D_real: 0.458 D_fake: 0.539 \n",
            "End of epoch 141 / 200 \t Time Taken: 75 sec\n",
            "update learning rate: 0.000120 -> 0.000118\n",
            "(epoch: 142, iters: 100, time: 0.847) G_GAN: 0.594 G_GAN_Feat: 0.721 G_VGG: 0.568 D_real: 0.568 D_fake: 0.446 \n",
            "End of epoch 142 / 200 \t Time Taken: 75 sec\n",
            "update learning rate: 0.000118 -> 0.000116\n",
            "(epoch: 143, iters: 100, time: 0.843) G_GAN: 0.509 G_GAN_Feat: 0.745 G_VGG: 0.511 D_real: 0.487 D_fake: 0.522 \n",
            "End of epoch 143 / 200 \t Time Taken: 74 sec\n",
            "update learning rate: 0.000116 -> 0.000114\n",
            "(epoch: 144, iters: 100, time: 0.851) G_GAN: 0.521 G_GAN_Feat: 0.850 G_VGG: 0.511 D_real: 0.476 D_fake: 0.489 \n",
            "End of epoch 144 / 200 \t Time Taken: 74 sec\n",
            "update learning rate: 0.000114 -> 0.000112\n",
            "(epoch: 145, iters: 100, time: 0.844) G_GAN: 0.547 G_GAN_Feat: 1.298 G_VGG: 0.510 D_real: 0.429 D_fake: 0.480 \n",
            "End of epoch 145 / 200 \t Time Taken: 75 sec\n",
            "update learning rate: 0.000112 -> 0.000110\n",
            "(epoch: 146, iters: 100, time: 0.848) G_GAN: 0.582 G_GAN_Feat: 1.946 G_VGG: 0.533 D_real: 0.426 D_fake: 0.474 \n",
            "End of epoch 146 / 200 \t Time Taken: 75 sec\n",
            "update learning rate: 0.000110 -> 0.000108\n",
            "(epoch: 147, iters: 100, time: 0.847) G_GAN: 0.642 G_GAN_Feat: 1.623 G_VGG: 0.544 D_real: 0.518 D_fake: 0.429 \n",
            "End of epoch 147 / 200 \t Time Taken: 75 sec\n",
            "update learning rate: 0.000108 -> 0.000106\n",
            "(epoch: 148, iters: 100, time: 0.848) G_GAN: 0.571 G_GAN_Feat: 1.967 G_VGG: 0.486 D_real: 0.476 D_fake: 0.545 \n",
            "End of epoch 148 / 200 \t Time Taken: 75 sec\n",
            "update learning rate: 0.000106 -> 0.000104\n",
            "(epoch: 149, iters: 100, time: 0.843) G_GAN: 0.859 G_GAN_Feat: 1.950 G_VGG: 0.548 D_real: 0.666 D_fake: 0.278 \n",
            "End of epoch 149 / 200 \t Time Taken: 75 sec\n",
            "update learning rate: 0.000104 -> 0.000102\n",
            "(epoch: 150, iters: 100, time: 0.845) G_GAN: 0.675 G_GAN_Feat: 2.146 G_VGG: 0.583 D_real: 0.487 D_fake: 0.402 \n",
            "saving the latest model (epoch 150, total_steps 15000)\n",
            "End of epoch 150 / 200 \t Time Taken: 79 sec\n",
            "saving the model at the end of epoch 150, iters 15000\n",
            "update learning rate: 0.000102 -> 0.000100\n",
            "(epoch: 151, iters: 100, time: 0.840) G_GAN: 0.691 G_GAN_Feat: 2.216 G_VGG: 0.540 D_real: 0.584 D_fake: 0.412 \n",
            "End of epoch 151 / 200 \t Time Taken: 75 sec\n",
            "update learning rate: 0.000100 -> 0.000098\n",
            "(epoch: 152, iters: 100, time: 0.844) G_GAN: 0.736 G_GAN_Feat: 2.231 G_VGG: 0.524 D_real: 0.537 D_fake: 0.344 \n",
            "End of epoch 152 / 200 \t Time Taken: 75 sec\n",
            "update learning rate: 0.000098 -> 0.000096\n",
            "(epoch: 153, iters: 100, time: 0.842) G_GAN: 0.478 G_GAN_Feat: 2.400 G_VGG: 0.521 D_real: 0.388 D_fake: 0.578 \n",
            "End of epoch 153 / 200 \t Time Taken: 74 sec\n",
            "update learning rate: 0.000096 -> 0.000094\n",
            "(epoch: 154, iters: 100, time: 0.847) G_GAN: 0.644 G_GAN_Feat: 2.169 G_VGG: 0.485 D_real: 0.526 D_fake: 0.460 \n",
            "End of epoch 154 / 200 \t Time Taken: 75 sec\n",
            "update learning rate: 0.000094 -> 0.000092\n",
            "(epoch: 155, iters: 100, time: 0.841) G_GAN: 0.545 G_GAN_Feat: 2.343 G_VGG: 0.523 D_real: 0.425 D_fake: 0.516 \n",
            "End of epoch 155 / 200 \t Time Taken: 75 sec\n",
            "update learning rate: 0.000092 -> 0.000090\n",
            "(epoch: 156, iters: 100, time: 0.850) G_GAN: 0.542 G_GAN_Feat: 2.340 G_VGG: 0.516 D_real: 0.457 D_fake: 0.517 \n",
            "End of epoch 156 / 200 \t Time Taken: 75 sec\n",
            "update learning rate: 0.000090 -> 0.000088\n",
            "(epoch: 157, iters: 100, time: 0.847) G_GAN: 0.572 G_GAN_Feat: 2.165 G_VGG: 0.520 D_real: 0.428 D_fake: 0.493 \n",
            "End of epoch 157 / 200 \t Time Taken: 75 sec\n",
            "update learning rate: 0.000088 -> 0.000086\n",
            "(epoch: 158, iters: 100, time: 0.843) G_GAN: 0.488 G_GAN_Feat: 2.277 G_VGG: 0.520 D_real: 0.364 D_fake: 0.542 \n",
            "End of epoch 158 / 200 \t Time Taken: 74 sec\n",
            "update learning rate: 0.000086 -> 0.000084\n",
            "(epoch: 159, iters: 100, time: 0.848) G_GAN: 0.695 G_GAN_Feat: 2.423 G_VGG: 0.492 D_real: 0.544 D_fake: 0.391 \n",
            "End of epoch 159 / 200 \t Time Taken: 75 sec\n",
            "update learning rate: 0.000084 -> 0.000082\n",
            "(epoch: 160, iters: 100, time: 0.846) G_GAN: 0.522 G_GAN_Feat: 2.479 G_VGG: 0.489 D_real: 0.410 D_fake: 0.512 \n",
            "saving the latest model (epoch 160, total_steps 16000)\n",
            "End of epoch 160 / 200 \t Time Taken: 79 sec\n",
            "saving the model at the end of epoch 160, iters 16000\n",
            "update learning rate: 0.000082 -> 0.000080\n",
            "(epoch: 161, iters: 100, time: 0.839) G_GAN: 0.562 G_GAN_Feat: 2.248 G_VGG: 0.466 D_real: 0.464 D_fake: 0.476 \n",
            "End of epoch 161 / 200 \t Time Taken: 75 sec\n",
            "update learning rate: 0.000080 -> 0.000078\n",
            "(epoch: 162, iters: 100, time: 0.846) G_GAN: 0.656 G_GAN_Feat: 2.128 G_VGG: 0.476 D_real: 0.446 D_fake: 0.393 \n",
            "End of epoch 162 / 200 \t Time Taken: 75 sec\n",
            "update learning rate: 0.000078 -> 0.000076\n",
            "(epoch: 163, iters: 100, time: 0.848) G_GAN: 0.516 G_GAN_Feat: 1.375 G_VGG: 0.482 D_real: 0.472 D_fake: 0.532 \n",
            "End of epoch 163 / 200 \t Time Taken: 75 sec\n",
            "update learning rate: 0.000076 -> 0.000074\n",
            "(epoch: 164, iters: 100, time: 0.851) G_GAN: 0.485 G_GAN_Feat: 1.436 G_VGG: 0.445 D_real: 0.465 D_fake: 0.548 \n",
            "End of epoch 164 / 200 \t Time Taken: 74 sec\n",
            "update learning rate: 0.000074 -> 0.000072\n",
            "(epoch: 165, iters: 100, time: 0.851) G_GAN: 0.546 G_GAN_Feat: 1.356 G_VGG: 0.451 D_real: 0.486 D_fake: 0.480 \n",
            "End of epoch 165 / 200 \t Time Taken: 75 sec\n",
            "update learning rate: 0.000072 -> 0.000070\n",
            "(epoch: 166, iters: 100, time: 0.846) G_GAN: 0.752 G_GAN_Feat: 1.381 G_VGG: 0.452 D_real: 0.602 D_fake: 0.353 \n",
            "End of epoch 166 / 200 \t Time Taken: 75 sec\n",
            "update learning rate: 0.000070 -> 0.000068\n",
            "(epoch: 167, iters: 100, time: 0.845) G_GAN: 0.587 G_GAN_Feat: 1.488 G_VGG: 0.456 D_real: 0.471 D_fake: 0.446 \n",
            "End of epoch 167 / 200 \t Time Taken: 75 sec\n",
            "update learning rate: 0.000068 -> 0.000066\n",
            "(epoch: 168, iters: 100, time: 0.850) G_GAN: 0.505 G_GAN_Feat: 1.421 G_VGG: 0.438 D_real: 0.442 D_fake: 0.519 \n",
            "End of epoch 168 / 200 \t Time Taken: 75 sec\n",
            "update learning rate: 0.000066 -> 0.000064\n",
            "(epoch: 169, iters: 100, time: 0.848) G_GAN: 0.588 G_GAN_Feat: 1.447 G_VGG: 0.454 D_real: 0.520 D_fake: 0.450 \n",
            "End of epoch 169 / 200 \t Time Taken: 74 sec\n",
            "update learning rate: 0.000064 -> 0.000062\n",
            "(epoch: 170, iters: 100, time: 0.843) G_GAN: 0.554 G_GAN_Feat: 1.831 G_VGG: 0.420 D_real: 0.449 D_fake: 0.481 \n",
            "saving the latest model (epoch 170, total_steps 17000)\n",
            "End of epoch 170 / 200 \t Time Taken: 79 sec\n",
            "saving the model at the end of epoch 170, iters 17000\n",
            "update learning rate: 0.000062 -> 0.000060\n",
            "(epoch: 171, iters: 100, time: 0.836) G_GAN: 0.565 G_GAN_Feat: 2.182 G_VGG: 0.485 D_real: 0.370 D_fake: 0.484 \n",
            "End of epoch 171 / 200 \t Time Taken: 75 sec\n",
            "update learning rate: 0.000060 -> 0.000058\n",
            "(epoch: 172, iters: 100, time: 0.847) G_GAN: 0.604 G_GAN_Feat: 1.941 G_VGG: 0.422 D_real: 0.456 D_fake: 0.443 \n",
            "End of epoch 172 / 200 \t Time Taken: 75 sec\n",
            "update learning rate: 0.000058 -> 0.000056\n",
            "(epoch: 173, iters: 100, time: 0.846) G_GAN: 0.536 G_GAN_Feat: 2.032 G_VGG: 0.480 D_real: 0.430 D_fake: 0.493 \n",
            "End of epoch 173 / 200 \t Time Taken: 74 sec\n",
            "update learning rate: 0.000056 -> 0.000054\n",
            "(epoch: 174, iters: 100, time: 0.848) G_GAN: 0.559 G_GAN_Feat: 1.988 G_VGG: 0.435 D_real: 0.453 D_fake: 0.473 \n",
            "End of epoch 174 / 200 \t Time Taken: 75 sec\n",
            "update learning rate: 0.000054 -> 0.000052\n",
            "(epoch: 175, iters: 100, time: 0.846) G_GAN: 0.513 G_GAN_Feat: 1.814 G_VGG: 0.451 D_real: 0.417 D_fake: 0.516 \n",
            "End of epoch 175 / 200 \t Time Taken: 75 sec\n",
            "update learning rate: 0.000052 -> 0.000050\n",
            "(epoch: 176, iters: 100, time: 0.848) G_GAN: 0.555 G_GAN_Feat: 1.767 G_VGG: 0.439 D_real: 0.467 D_fake: 0.478 \n",
            "End of epoch 176 / 200 \t Time Taken: 75 sec\n",
            "update learning rate: 0.000050 -> 0.000048\n",
            "(epoch: 177, iters: 100, time: 0.846) G_GAN: 0.516 G_GAN_Feat: 1.988 G_VGG: 0.414 D_real: 0.476 D_fake: 0.508 \n",
            "End of epoch 177 / 200 \t Time Taken: 75 sec\n",
            "update learning rate: 0.000048 -> 0.000046\n",
            "(epoch: 178, iters: 100, time: 0.846) G_GAN: 0.504 G_GAN_Feat: 1.814 G_VGG: 0.410 D_real: 0.432 D_fake: 0.526 \n",
            "End of epoch 178 / 200 \t Time Taken: 75 sec\n",
            "update learning rate: 0.000046 -> 0.000044\n",
            "(epoch: 179, iters: 100, time: 0.844) G_GAN: 0.524 G_GAN_Feat: 1.894 G_VGG: 0.437 D_real: 0.474 D_fake: 0.507 \n",
            "End of epoch 179 / 200 \t Time Taken: 75 sec\n",
            "update learning rate: 0.000044 -> 0.000042\n",
            "(epoch: 180, iters: 100, time: 0.847) G_GAN: 0.600 G_GAN_Feat: 1.895 G_VGG: 0.428 D_real: 0.504 D_fake: 0.432 \n",
            "saving the latest model (epoch 180, total_steps 18000)\n",
            "End of epoch 180 / 200 \t Time Taken: 79 sec\n",
            "saving the model at the end of epoch 180, iters 18000\n",
            "update learning rate: 0.000042 -> 0.000040\n",
            "(epoch: 181, iters: 100, time: 0.838) G_GAN: 0.583 G_GAN_Feat: 1.753 G_VGG: 0.429 D_real: 0.502 D_fake: 0.447 \n",
            "End of epoch 181 / 200 \t Time Taken: 75 sec\n",
            "update learning rate: 0.000040 -> 0.000038\n",
            "(epoch: 182, iters: 100, time: 0.847) G_GAN: 0.547 G_GAN_Feat: 1.891 G_VGG: 0.424 D_real: 0.517 D_fake: 0.481 \n",
            "End of epoch 182 / 200 \t Time Taken: 75 sec\n",
            "update learning rate: 0.000038 -> 0.000036\n",
            "(epoch: 183, iters: 100, time: 0.851) G_GAN: 0.584 G_GAN_Feat: 1.864 G_VGG: 0.423 D_real: 0.496 D_fake: 0.443 \n",
            "End of epoch 183 / 200 \t Time Taken: 75 sec\n",
            "update learning rate: 0.000036 -> 0.000034\n",
            "(epoch: 184, iters: 100, time: 0.848) G_GAN: 0.561 G_GAN_Feat: 1.643 G_VGG: 0.399 D_real: 0.521 D_fake: 0.475 \n",
            "End of epoch 184 / 200 \t Time Taken: 75 sec\n",
            "update learning rate: 0.000034 -> 0.000032\n",
            "(epoch: 185, iters: 100, time: 0.844) G_GAN: 0.545 G_GAN_Feat: 2.062 G_VGG: 0.423 D_real: 0.471 D_fake: 0.488 \n",
            "End of epoch 185 / 200 \t Time Taken: 74 sec\n",
            "update learning rate: 0.000032 -> 0.000030\n",
            "(epoch: 186, iters: 100, time: 0.846) G_GAN: 0.559 G_GAN_Feat: 1.754 G_VGG: 0.409 D_real: 0.494 D_fake: 0.465 \n",
            "End of epoch 186 / 200 \t Time Taken: 75 sec\n",
            "update learning rate: 0.000030 -> 0.000028\n",
            "(epoch: 187, iters: 100, time: 0.842) G_GAN: 0.564 G_GAN_Feat: 1.969 G_VGG: 0.409 D_real: 0.471 D_fake: 0.463 \n",
            "End of epoch 187 / 200 \t Time Taken: 75 sec\n",
            "update learning rate: 0.000028 -> 0.000026\n",
            "(epoch: 188, iters: 100, time: 0.847) G_GAN: 0.560 G_GAN_Feat: 1.703 G_VGG: 0.390 D_real: 0.486 D_fake: 0.463 \n",
            "End of epoch 188 / 200 \t Time Taken: 75 sec\n",
            "update learning rate: 0.000026 -> 0.000024\n",
            "(epoch: 189, iters: 100, time: 0.845) G_GAN: 0.553 G_GAN_Feat: 2.074 G_VGG: 0.397 D_real: 0.459 D_fake: 0.467 \n",
            "End of epoch 189 / 200 \t Time Taken: 75 sec\n",
            "update learning rate: 0.000024 -> 0.000022\n",
            "(epoch: 190, iters: 100, time: 0.845) G_GAN: 0.557 G_GAN_Feat: 1.908 G_VGG: 0.373 D_real: 0.502 D_fake: 0.465 \n",
            "saving the latest model (epoch 190, total_steps 19000)\n",
            "End of epoch 190 / 200 \t Time Taken: 79 sec\n",
            "saving the model at the end of epoch 190, iters 19000\n",
            "update learning rate: 0.000022 -> 0.000020\n",
            "(epoch: 191, iters: 100, time: 0.834) G_GAN: 0.521 G_GAN_Feat: 1.760 G_VGG: 0.386 D_real: 0.458 D_fake: 0.502 \n",
            "End of epoch 191 / 200 \t Time Taken: 75 sec\n",
            "update learning rate: 0.000020 -> 0.000018\n",
            "(epoch: 192, iters: 100, time: 0.846) G_GAN: 0.550 G_GAN_Feat: 1.711 G_VGG: 0.388 D_real: 0.469 D_fake: 0.477 \n",
            "End of epoch 192 / 200 \t Time Taken: 75 sec\n",
            "update learning rate: 0.000018 -> 0.000016\n",
            "(epoch: 193, iters: 100, time: 0.846) G_GAN: 0.515 G_GAN_Feat: 1.885 G_VGG: 0.368 D_real: 0.462 D_fake: 0.500 \n",
            "End of epoch 193 / 200 \t Time Taken: 75 sec\n",
            "update learning rate: 0.000016 -> 0.000014\n",
            "(epoch: 194, iters: 100, time: 0.843) G_GAN: 0.543 G_GAN_Feat: 1.815 G_VGG: 0.391 D_real: 0.488 D_fake: 0.476 \n",
            "End of epoch 194 / 200 \t Time Taken: 75 sec\n",
            "update learning rate: 0.000014 -> 0.000012\n",
            "(epoch: 195, iters: 100, time: 0.846) G_GAN: 0.501 G_GAN_Feat: 1.682 G_VGG: 0.367 D_real: 0.445 D_fake: 0.519 \n",
            "End of epoch 195 / 200 \t Time Taken: 75 sec\n",
            "update learning rate: 0.000012 -> 0.000010\n",
            "(epoch: 196, iters: 100, time: 0.842) G_GAN: 0.557 G_GAN_Feat: 1.813 G_VGG: 0.378 D_real: 0.487 D_fake: 0.463 \n",
            "End of epoch 196 / 200 \t Time Taken: 75 sec\n",
            "update learning rate: 0.000010 -> 0.000008\n",
            "(epoch: 197, iters: 100, time: 0.842) G_GAN: 0.554 G_GAN_Feat: 1.863 G_VGG: 0.383 D_real: 0.490 D_fake: 0.462 \n",
            "End of epoch 197 / 200 \t Time Taken: 74 sec\n",
            "update learning rate: 0.000008 -> 0.000006\n",
            "(epoch: 198, iters: 100, time: 0.849) G_GAN: 0.542 G_GAN_Feat: 1.619 G_VGG: 0.374 D_real: 0.492 D_fake: 0.478 \n",
            "End of epoch 198 / 200 \t Time Taken: 75 sec\n",
            "update learning rate: 0.000006 -> 0.000004\n",
            "(epoch: 199, iters: 100, time: 0.845) G_GAN: 0.562 G_GAN_Feat: 2.056 G_VGG: 0.361 D_real: 0.454 D_fake: 0.459 \n",
            "End of epoch 199 / 200 \t Time Taken: 75 sec\n",
            "update learning rate: 0.000004 -> 0.000002\n",
            "(epoch: 200, iters: 100, time: 0.846) G_GAN: 0.563 G_GAN_Feat: 1.966 G_VGG: 0.361 D_real: 0.482 D_fake: 0.457 \n",
            "saving the latest model (epoch 200, total_steps 20000)\n",
            "End of epoch 200 / 200 \t Time Taken: 79 sec\n",
            "saving the model at the end of epoch 200, iters 20000\n",
            "update learning rate: 0.000002 -> 0.000000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "67Ph3f7OQC_E",
        "outputId": "f5a820ba-cb15-44b1-e9f0-410ce073f512"
      },
      "source": [
        "!pip install scipy==1.2.0"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting scipy==1.2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/67/e6/6d4edaceee6a110ecf6f318482f5229792f143e468b34a631f5a0899f56d/scipy-1.2.0-cp36-cp36m-manylinux1_x86_64.whl (26.6MB)\n",
            "\u001b[K     |████████████████████████████████| 26.6MB 44.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python3.6/dist-packages (from scipy==1.2.0) (1.18.5)\n",
            "\u001b[31mERROR: umap-learn 0.4.6 has requirement scipy>=1.3.1, but you'll have scipy 1.2.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: scipy\n",
            "  Found existing installation: scipy 1.4.1\n",
            "    Uninstalling scipy-1.4.1:\n",
            "      Successfully uninstalled scipy-1.4.1\n",
            "Successfully installed scipy-1.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lkOgIDF6JyN9",
        "outputId": "0bc0751c-2cbe-4599-bb1e-592728e0a462"
      },
      "source": [
        "!pip install torch==1.6.0+cu101 torchvision==0.7.0+cu101 -f https://download.pytorch.org/whl/torch_stable.html"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Collecting torch==1.6.0+cu101\n",
            "\u001b[?25l  Downloading https://download.pytorch.org/whl/cu101/torch-1.6.0%2Bcu101-cp36-cp36m-linux_x86_64.whl (708.0MB)\n",
            "\u001b[K     |████████████████████████████████| 708.0MB 24kB/s \n",
            "\u001b[?25hCollecting torchvision==0.7.0+cu101\n",
            "\u001b[?25l  Downloading https://download.pytorch.org/whl/cu101/torchvision-0.7.0%2Bcu101-cp36-cp36m-linux_x86_64.whl (5.9MB)\n",
            "\u001b[K     |████████████████████████████████| 5.9MB 58.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch==1.6.0+cu101) (1.18.5)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch==1.6.0+cu101) (0.16.0)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision==0.7.0+cu101) (7.0.0)\n",
            "Installing collected packages: torch, torchvision\n",
            "  Found existing installation: torch 1.6.0\n",
            "    Uninstalling torch-1.6.0:\n",
            "      Successfully uninstalled torch-1.6.0\n",
            "  Found existing installation: torchvision 0.7.0\n",
            "    Uninstalling torchvision-0.7.0:\n",
            "      Successfully uninstalled torchvision-0.7.0\n",
            "Successfully installed torch-1.6.0+cu101 torchvision-0.7.0+cu101\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UoSRYUZUIVvj",
        "outputId": "1860ad27-f902-4b4d-aed0-5ca3823a5222"
      },
      "source": [
        "!pip install tensorflow==1.15.0"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==1.15.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3f/98/5a99af92fb911d7a88a0005ad55005f35b4c1ba8d75fba02df726cd936e6/tensorflow-1.15.0-cp36-cp36m-manylinux2010_x86_64.whl (412.3MB)\n",
            "\u001b[K     |████████████████████████████████| 412.3MB 40kB/s \n",
            "\u001b[?25hCollecting tensorboard<1.16.0,>=1.15.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1e/e9/d3d747a97f7188f48aa5eda486907f3b345cd409f0a0850468ba867db246/tensorboard-1.15.0-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 58.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.12.1)\n",
            "Collecting gast==0.2.2\n",
            "  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (3.12.4)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.18.5)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.1.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.15.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.33.2)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.1.2)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (0.8.1)\n",
            "Collecting tensorflow-estimator==1.15.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/62/2ee9cd74c9fa2fa450877847ba560b260f5d0fb70ee0595203082dafcc9d/tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503kB)\n",
            "\u001b[K     |████████████████████████████████| 512kB 46.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (3.3.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (0.2.0)\n",
            "Collecting keras-applications>=1.0.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 8.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (0.10.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (0.35.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (1.0.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (50.3.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (3.3.3)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow==1.15.0) (2.10.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (2.0.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (3.4.0)\n",
            "Building wheels for collected packages: gast\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-cp36-none-any.whl size=7542 sha256=e021fe19334150ba4c4dbefdf9ac4faa1570acc3992592b7a791500c16ad6504\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n",
            "Successfully built gast\n",
            "\u001b[31mERROR: tensorflow-probability 0.11.0 has requirement gast>=0.3.2, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n",
            "Installing collected packages: tensorboard, gast, tensorflow-estimator, keras-applications, tensorflow\n",
            "  Found existing installation: tensorboard 2.3.0\n",
            "    Uninstalling tensorboard-2.3.0:\n",
            "      Successfully uninstalled tensorboard-2.3.0\n",
            "  Found existing installation: gast 0.3.3\n",
            "    Uninstalling gast-0.3.3:\n",
            "      Successfully uninstalled gast-0.3.3\n",
            "  Found existing installation: tensorflow-estimator 2.3.0\n",
            "    Uninstalling tensorflow-estimator-2.3.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.3.0\n",
            "  Found existing installation: tensorflow 2.3.0\n",
            "    Uninstalling tensorflow-2.3.0:\n",
            "      Successfully uninstalled tensorflow-2.3.0\n",
            "Successfully installed gast-0.2.2 keras-applications-1.0.8 tensorboard-1.15.0 tensorflow-1.15.0 tensorflow-estimator-1.15.1\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}